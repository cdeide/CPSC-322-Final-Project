{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 322 Project Proposal\n",
    "####    Connor Deide and Liam Navarre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description \n",
    "\n",
    "#### Data Files:  \n",
    "* the_office_series \n",
    "* the_office_episodes  \n",
    "#### Source:  \n",
    "* Kaggle.com  \n",
    "  \n",
    "#### Format: \n",
    "* CSV file  \n",
    "  \n",
    "#### Contents:  \n",
    "* the_office_series\n",
    "    * Episode\n",
    "    * Season\n",
    "    * EpisodeTitle\n",
    "    * About \n",
    "    * Ratings\n",
    "    * Votes\n",
    "    * Viewership\n",
    "    * Duration \n",
    "    * Date\n",
    "    * GuestStars  \n",
    "  \n",
    "  \n",
    "* the_office_episodes  \n",
    "    * season\n",
    "    * episode_num_in_season\n",
    "    * episode_num_overall\n",
    "    * title\n",
    "    * directed_by\n",
    "    * written_by\n",
    "    * original_air_date\n",
    "    * prod_code\n",
    "    * us_viewers\n",
    "\n",
    "#### Description:  \n",
    "We will be using the normalized  Votes, Viewership, Duration, and season numerical values and the discretized about categorical values in order to make a prediction on the ratings of an episode. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation and Technical Merit \n",
    "\n",
    "#### Anticipated Challenges in Preprocessing:  \n",
    "We will have to make a personalized discretizer for the about section of the_office_series file. We are planning to also explore the data based on what characters are present in the episode and how that affects the ratings. We also plan to either join the two files together and drop redudant columns or grab the director and writer columns from the the_office_episodes file because the directors and writers aren't present in the_office_series file. This is so we are able to make predictions on the ratings using the director and writer. We also will be normalizing the numerical values so they fit within the range of 0 and 1\n",
    "\n",
    "#### Attribute Handling:  \n",
    "The Data set we are using does not contain a large number of attributes so our requirement to pare down the attributes is minimal. Although the we have a small set of attributes, we will be removing redundant data between the join. We will also be removing attributes that are not relevant in regards to the predictions we're making. Such as us_viewers in the_office_episode file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Impact  \n",
    "\n",
    "#### Usefulness of Results:  \n",
    "These results are useful because a network would be concerned on the results of their tv show. So if we are able to find a positive correlation between attributes it would be in the favor of the network to incorporate those for future episodes. \n",
    "\n",
    "#### Stakeholders:  \n",
    "The stakeholders of this project would be the network and the consumers of the television show. This is because the success of the show has a direct impact on the stakeholders and the success of the show is directly caused by the consumer. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
